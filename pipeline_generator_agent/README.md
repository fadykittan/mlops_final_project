# Pipeline Generator Agent

This agent generates Airflow DAGs from structured ETL pipeline specifications in JSON format.

## Overview

The Pipeline Generator Agent takes a JSON specification (generated by the Parser Agent) and converts it into a complete, executable Airflow DAG Python code. It follows the same architectural pattern as the Parser Agent for consistency.

## Features

- **JSON to Airflow DAG**: Converts structured pipeline specifications into ready-to-run Airflow DAG code
- **Google Gemini Integration**: Uses Google's Gemini AI model for intelligent code generation
- **Direct Python Output**: Returns clean Python code without JSON wrapping
- **Auto File Saving**: Automatically saves generated DAGs to files
- **Flask API**: Provides REST API endpoints for integration with other services
- **Error Handling**: Comprehensive error handling and logging

## Files

- `pipeline_generator_agent.py` - Main agent implementation
- `app.py` - Flask web application for API endpoints
- `system_prompt.txt` - System prompt for the AI model
- `config.env` - Environment configuration (API keys)
- `README.md` - This documentation

## Usage

### Command Line

```bash
python pipeline_generator_agent.py
```

### Flask API

```bash
python app.py
```

The API will be available at `http://localhost:5001`

#### Endpoints

- `POST /generate` - Generate Airflow DAG from pipeline specification
- `GET /health` - Health check endpoint

#### Example API Request

```json
{
  "pipeline_spec": {
    "user_request": "Create an ETL pipeline to pull daily sales data from the Shopify API",
    "source": {
      "type": "API",
      "endpoint_or_table": "google.com/api/v1/sales",
      "query_or_filter": null
    },
    "destination": {
      "type": "Postgres",
      "path": "daily_sales"
    },
    "transformations": [
      {
        "step_number": 1,
        "language": "Python",
        "operation": "Null Customer ID Handling",
        "target": "customer_id"
      }
    ],
    "confidence": 0.8
  }
}
```

## Output Format

The agent returns clean, ready-to-run Python code for Airflow DAGs. The generated code includes:

- Complete imports and dependencies
- DAG configuration with proper scheduling
- Extract, Transform, and Load tasks
- Error handling and logging
- Task dependencies and orchestration
- Production-ready code structure

The generated DAGs are automatically saved to the `output/` directory with descriptive filenames.

## Generated DAG Features

- **Extract Tasks**: API calls, database queries, file reads
- **Transform Tasks**: Data cleaning, validation, processing
- **Load Tasks**: Writing to destination databases
- **Task Dependencies**: Proper task ordering using `>>` operator
- **Error Handling**: Comprehensive error handling and logging
- **Connection Management**: Uses Airflow connections for database access
- **Scheduling**: Configurable schedule intervals

## Dependencies

- Flask
- langchain
- langchain-google-genai
- google-generativeai
- python-dotenv

## Configuration

Set your Google API key in `config.env`:

```
GOOGLE_API_KEY=your_api_key_here
```

## Example Generated DAG

The agent generates complete Airflow DAGs with proper imports, task definitions, and dependencies. The generated code includes:

- Proper error handling
- Logging configuration
- Database connection management
- Data transformation logic
- Task orchestration

## Integration

This agent is designed to work seamlessly with the Parser Agent in a complete MLOps pipeline generation workflow:

1. **Parser Agent** converts natural language to structured JSON
2. **Pipeline Generator Agent** converts JSON to Airflow DAG code
3. **Generated DAG** can be deployed to Airflow for execution
